{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc6181fa",
   "metadata": {},
   "source": [
    "# Automatic Speech Recognition with Transducer Models\n",
    "\n",
    "This notebook is a basic tutorial for creating a Transducer ASR model and then training it on a small dataset (AN4). It includes discussion relevant to reducing memory issues when training such models and demonstrates how to change the decoding strategy after training. Finally, it also provides a brief glimpse of extracting alignment information from a trained Transducer model.\n",
    "\n",
    "As we will see in this tutorial, apart from the differences in the config and the class used to instantiate the model, nearly all steps are precisely similar to any CTC-based model training. Many concepts such as data loader setup, optimization setup, pre-trained checkpoint weight loading will be nearly identical between CTC and Transducer models.\n",
    "\n",
    "In essence, NeMo makes it seamless to take a config for a CTC ASR model, add in a few components related to Transducers (often without any modifications) and use a different class to instantiate a Transducer model!\n",
    "\n",
    "--------\n",
    "\n",
    "**Note**: It is assumed that the previous tutorial - \"Intro-to-Transducers\" has been reviewed, and there is some familiarity with the config components of transducer models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d4c774",
   "metadata": {},
   "source": [
    "# Preparing the dataset\n",
    "\n",
    "In this tutorial, we will be utilizing the `AN4`dataset - also known as the Alphanumeric dataset, which was collected and published by Carnegie Mellon University. It consists of recordings of people spelling out addresses, names, telephone numbers, etc., one letter or number at a time and their corresponding transcripts. We choose to use AN4 for this tutorial because it is relatively small, with 948 training and 130 test utterances, and so it trains quickly.\n",
    "\n",
    "Let's first download the preparation script from NeMo's scripts directory -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e736d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "Tarfile already exists.\n",
      "Finished conversion.\n",
      "******\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wget\n",
    "import tarfile\n",
    "import subprocess\n",
    "import glob\n",
    "\n",
    "data_dir = \"datasets\"\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "  os.makedirs(data_dir)\n",
    "\n",
    "# Download the dataset. This will take a few moments...\n",
    "print(\"******\")\n",
    "if not os.path.exists(data_dir + '/an4_sphere.tar.gz'):\n",
    "    an4_url = 'https://dldata-public.s3.us-east-2.amazonaws.com/an4_sphere.tar.gz'\n",
    "    an4_path = wget.download(an4_url, data_dir)\n",
    "    print(f\"Dataset downloaded at: {an4_path}\")\n",
    "else:\n",
    "    print(\"Tarfile already exists.\")\n",
    "    an4_path = data_dir + '/an4_sphere.tar.gz'\n",
    "\n",
    "\n",
    "if not os.path.exists(data_dir + '/an4/'):\n",
    "    # Untar and convert .sph to .wav (using sox)\n",
    "    tar = tarfile.open(an4_path)\n",
    "    tar.extractall(path=data_dir)\n",
    "\n",
    "    print(\"Converting .sph to .wav...\")\n",
    "    sph_list = glob.glob(data_dir + '/an4/**/*.sph', recursive=True)\n",
    "    for sph_path in sph_list:\n",
    "        wav_path = sph_path[:-4] + '.wav'\n",
    "        cmd = [\"sox\", sph_path, wav_path]\n",
    "        subprocess.run(cmd)\n",
    "\n",
    "print(\"Finished conversion.\\n******\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40cb98c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "***Done***\n"
     ]
    }
   ],
   "source": [
    "# --- Building Manifest Files --- #\n",
    "import json\n",
    "import librosa\n",
    "\n",
    "# Function to build a manifest\n",
    "def build_manifest(transcripts_path, manifest_path, wav_path):\n",
    "    with open(transcripts_path, 'r') as fin:\n",
    "        with open(manifest_path, 'w') as fout:\n",
    "            for line in fin:\n",
    "                # Lines look like this:\n",
    "                # <s> transcript </s> (fileID)\n",
    "                transcript = line[: line.find('(')-1].lower()\n",
    "                transcript = transcript.replace('<s>', '').replace('</s>', '')\n",
    "                transcript = transcript.strip()\n",
    "\n",
    "                file_id = line[line.find('(')+1 : -2]  # e.g. \"cen4-fash-b\"\n",
    "                audio_path = os.path.join(\n",
    "                    data_dir, wav_path,\n",
    "                    file_id[file_id.find('-')+1 : file_id.rfind('-')],\n",
    "                    file_id + '.wav')\n",
    "\n",
    "                duration = librosa.core.get_duration(path=audio_path)\n",
    "\n",
    "                # Write the metadata to the manifest\n",
    "                metadata = {\n",
    "                    \"audio_filepath\": audio_path,\n",
    "                    \"duration\": duration,\n",
    "                    \"text\": transcript\n",
    "                }\n",
    "                json.dump(metadata, fout)\n",
    "                fout.write('\\n')\n",
    "\n",
    "# Building Manifests\n",
    "print(\"******\")\n",
    "train_transcripts = os.path.join(data_dir, 'an4/etc/an4_train.transcription')\n",
    "train_manifest = os.path.join(data_dir, 'an4/train_manifest.json')\n",
    "if not os.path.isfile(train_manifest):\n",
    "    build_manifest(train_transcripts, train_manifest, 'an4/wav/an4_clstk')\n",
    "    print(\"Training manifest created.\")\n",
    "\n",
    "test_transcripts = os.path.join(data_dir, 'an4/etc/an4_test.transcription')\n",
    "test_manifest = os.path.join(data_dir, 'an4/test_manifest.json')\n",
    "if not os.path.isfile(test_manifest):\n",
    "    build_manifest(test_transcripts, test_manifest, 'an4/wav/an4test_clstk')\n",
    "    print(\"Test manifest created.\")\n",
    "print(\"***Done***\")\n",
    "# Manifest filepaths\n",
    "TRAIN_MANIFEST = train_manifest\n",
    "TEST_MANIFEST = test_manifest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34598038",
   "metadata": {},
   "source": [
    "## Preparing the tokenizer\n",
    "\n",
    "Now that we have a dataset ready, we need to decide whether to use a character-based model or a sub-word-based model. For completeness' sake, we will use a tokenizer based model so that we can leverage a modern encoder architecture like ContextNet or Conformer-T."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b9dd584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Finished extracting manifest : datasets/an4/train_manifest.json\n",
      "INFO:root:Finished extracting all manifests ! Number of sentences : 948\n",
      "[NeMo I 2025-07-18 16:10:48 sentencepiece_tokenizer:425] Processing tokenizers/text_corpus/document.txt and store at tokenizers/tokenizer_spe_bpe_v64\n",
      "sentencepiece_trainer.cc(178) LOG(INFO) Running command: --input=tokenizers/text_corpus/document.txt --model_prefix=tokenizers/tokenizer_spe_bpe_v64/tokenizer --vocab_size=64 --shuffle_input_sentence=true --hard_vocab_limit=false --model_type=bpe --character_coverage=1.0 --bos_id=-1 --eos_id=-1 --remove_extra_whitespaces=false\n",
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: tokenizers/text_corpus/document.txt\n",
      "  input_format: \n",
      "  model_prefix: tokenizers/tokenizer_spe_bpe_v64/tokenizer\n",
      "  model_type: BPE\n",
      "  vocab_size: 64\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 0\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: -1\n",
      "  eos_id: -1\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 0\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: tokenizers/text_corpus/document.txt\n",
      "trainer_interface.cc(409) LOG(INFO) Loaded all 948 sentences\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(539) LOG(INFO) all chars count=18802\n",
      "trainer_interface.cc(560) LOG(INFO) Alphabet size=27\n",
      "trainer_interface.cc(561) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 948 sentences.\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 948\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 99\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=718 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=190 size=20 all=208 active=181 piece=ee\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: tokenizers/tokenizer_spe_bpe_v64/tokenizer.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: tokenizers/tokenizer_spe_bpe_v64/tokenizer.vocab\n",
      "Serialized tokenizer at location : tokenizers/tokenizer_spe_bpe_v64\n",
      "INFO:root:Done!\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = 64  # can be any value above 29\n",
    "TOKENIZER_TYPE = \"spe\"  # can be wpe or spe\n",
    "SPE_TYPE = \"bpe\"  # can be bpe or unigram\n",
    "\n",
    "# ------------------------------------------------------------------- #\n",
    "!rm -r tokenizers/\n",
    "\n",
    "if not os.path.exists(\"tokenizers\"):\n",
    "  os.makedirs(\"tokenizers\")\n",
    "\n",
    "!python scripts/process_asr_text_tokenizer.py \\\n",
    "   --manifest=$TRAIN_MANIFEST \\\n",
    "   --data_root=\"tokenizers\" \\\n",
    "   --tokenizer=$TOKENIZER_TYPE \\\n",
    "   --spe_type=$SPE_TYPE \\\n",
    "   --no_lower_case \\\n",
    "   --log \\\n",
    "   --vocab_size=$VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b3ba900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer path\n",
    "if TOKENIZER_TYPE == 'spe':\n",
    "  TOKENIZER = os.path.join(\"tokenizers\", f\"tokenizer_spe_{SPE_TYPE}_v{VOCAB_SIZE}\")\n",
    "  TOKENIZER_TYPE_CFG = \"bpe\"\n",
    "else:\n",
    "  TOKENIZER = os.path.join(\"tokenizers\", f\"tokenizer_wpe_v{VOCAB_SIZE}\")\n",
    "  TOKENIZER_TYPE_CFG = \"wpe\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a05baf",
   "metadata": {},
   "source": [
    "## Load model config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23990f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf, open_dict\n",
    "\n",
    "config = OmegaConf.load(\"configs/contextnet_rnnt_1.yaml\")\n",
    "# config = OmegaConf.load(\"configs/fast-conformer_transducer_bpe.yaml\")\n",
    "config.model.train_ds.manifest_filepath = TRAIN_MANIFEST\n",
    "config.model.validation_ds.manifest_filepath = TEST_MANIFEST\n",
    "config.model.test_ds.manifest_filepath = TEST_MANIFEST\n",
    "\n",
    "config.model.tokenizer.dir = TOKENIZER\n",
    "config.model.tokenizer.type = TOKENIZER_TYPE_CFG\n",
    "\n",
    "# Finally, let's remove logging of samples and the warmup since the dataset is small (similar to CTC models)\n",
    "config.model.log_prediction = False\n",
    "config.model.optim.sched.warmup_steps = None\n",
    "\n",
    "config.model.spec_augment.freq_masks = 0\n",
    "config.model.spec_augment.time_masks = 0\n",
    "\n",
    "# config.model.encoder.jasper = config.model.encoder.jasper[:5]\n",
    "# config.model.encoder.jasper[-1].filters = '${model.model_defaults.enc_hidden}'\n",
    "config.model.encoder.n_layers = 6\n",
    "# config.model.encoder.d_model = 176\n",
    "config.model.encoder.n_heads = 1\n",
    "# config.model.train_ds.max_duration = 5\n",
    "config.model.encoder.conv_kernel_size = 17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92491e28",
   "metadata": {},
   "source": [
    "## Initialize a Transducer ASR Model\n",
    "\n",
    "Finally, let us create a Transducer model, which is as easy as changing a line of import if you already have a script to create CTC models. We will use a small model since the dataset is just 5 hours of speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0a0ec1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/nemo/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from lightning.pytorch import Trainer\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  accelerator = 'gpu'\n",
    "else:\n",
    "  accelerator = 'gpu'\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "# Initialize a Trainer for the Transducer model\n",
    "trainer = Trainer(devices=1, accelerator=accelerator, max_epochs=EPOCHS,\n",
    "                  enable_checkpointing=False, logger=False,\n",
    "                  log_every_n_steps=5, check_val_every_n_epoch=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15d3f6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-07-18 16:10:55 mixins:181] Tokenizer SentencePieceTokenizer initialized with 64 tokens\n",
      "[NeMo I 2025-07-18 16:10:55 collections:201] Dataset loaded with 948 files totalling 0.71 hours\n",
      "[NeMo I 2025-07-18 16:10:55 collections:202] 0 files were filtered totalling 0.00 hours\n",
      "[NeMo I 2025-07-18 16:10:55 collections:201] Dataset loaded with 130 files totalling 0.10 hours\n",
      "[NeMo I 2025-07-18 16:10:55 collections:202] 0 files were filtered totalling 0.00 hours\n",
      "[NeMo I 2025-07-18 16:10:55 collections:201] Dataset loaded with 130 files totalling 0.10 hours\n",
      "[NeMo I 2025-07-18 16:10:55 collections:202] 0 files were filtered totalling 0.00 hours\n",
      "[NeMo I 2025-07-18 16:10:55 features:305] PADDING: 16\n",
      "[NeMo I 2025-07-18 16:10:56 rnnt_models:226] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.001, 'clamp': -1.0}\n",
      "[NeMo I 2025-07-18 16:10:56 rnnt_models:226] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.001, 'clamp': -1.0}\n",
      "[NeMo I 2025-07-18 16:10:56 rnnt_models:226] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.001, 'clamp': -1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  | Name              | Type                              | Params | Mode \n",
       "--------------------------------------------------------------------------------\n",
       "0 | preprocessor      | AudioToMelSpectrogramPreprocessor | 0      | train\n",
       "1 | encoder           | ConformerEncoder                  | 5.1 M  | train\n",
       "2 | decoder           | RNNTDecoder                       | 3.3 M  | train\n",
       "3 | joint             | RNNTJoint                         | 565 K  | train\n",
       "4 | loss              | RNNTLoss                          | 0      | train\n",
       "5 | spec_augmentation | SpectrogramAugmentation           | 0      | train\n",
       "6 | wer               | WER                               | 0      | train\n",
       "--------------------------------------------------------------------------------\n",
       "9.0 M     Trainable params\n",
       "0         Non-trainable params\n",
       "9.0 M     Total params\n",
       "35.964    Total estimated model params size (MB)\n",
       "201       Modules in train mode\n",
       "0         Modules in eval mode"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nemo.collections.asr as nemo_asr\n",
    "model = nemo_asr.models.EncDecRNNTBPEModel(cfg=config.model, trainer=trainer)\n",
    "model.summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d9d097",
   "metadata": {},
   "source": [
    "# Training on AN4\n",
    "\n",
    "Now that the model is ready, we can finally train it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9bb9ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-07-18 16:10:56 exp_manager:561] ExpManager schema\n",
      "[NeMo I 2025-07-18 16:10:56 exp_manager:562] {'explicit_log_dir': None, 'exp_dir': None, 'name': None, 'version': None, 'use_datetime_version': True, 'resume_if_exists': False, 'resume_past_end': False, 'resume_ignore_no_checkpoint': False, 'resume_from_checkpoint': None, 'create_tensorboard_logger': True, 'summary_writer_kwargs': None, 'create_wandb_logger': False, 'wandb_logger_kwargs': None, 'create_mlflow_logger': False, 'mlflow_logger_kwargs': {'experiment_name': None, 'tracking_uri': None, 'tags': None, 'save_dir': './mlruns', 'prefix': '', 'artifact_location': None, 'run_id': None, 'log_model': False}, 'create_dllogger_logger': False, 'dllogger_logger_kwargs': {'verbose': False, 'stdout': False, 'json_file': './dllogger.json'}, 'create_clearml_logger': False, 'clearml_logger_kwargs': {'project': None, 'task': None, 'connect_pytorch': False, 'model_name': None, 'tags': None, 'log_model': False, 'log_cfg': False, 'log_metrics': False}, 'create_neptune_logger': False, 'neptune_logger_kwargs': None, 'create_checkpoint_callback': True, 'checkpoint_callback_params': {'filepath': None, 'dirpath': None, 'filename': None, 'monitor': 'val_loss', 'verbose': True, 'save_last': True, 'save_top_k': 3, 'save_weights_only': False, 'mode': 'min', 'auto_insert_metric_name': True, 'every_n_epochs': 1, 'every_n_train_steps': None, 'train_time_interval': None, 'prefix': None, 'postfix': '.nemo', 'save_best_model': False, 'always_save_nemo': False, 'save_nemo_on_train_end': True, 'model_parallel_size': None, 'save_on_train_epoch_end': False, 'async_save': False, 'save_last_n_optim_states': -1}, 'create_early_stopping_callback': False, 'early_stopping_callback_params': {'monitor': 'val_loss', 'mode': 'min', 'min_delta': 0.001, 'patience': 10, 'verbose': True, 'strict': True, 'check_finite': True, 'stopping_threshold': None, 'divergence_threshold': None, 'check_on_train_epoch_end': None, 'log_rank_zero_only': False}, 'create_preemption_callback': True, 'files_to_copy': None, 'log_step_timing': True, 'log_delta_step_timing': False, 'step_timing_kwargs': {'reduction': 'mean', 'sync_cuda': False, 'buffer_size': 1}, 'log_local_rank_0_only': False, 'log_global_rank_0_only': False, 'disable_validation_on_resume': True, 'ema': {'enable': False, 'decay': 0.999, 'cpu_offload': False, 'validate_original_weights': False, 'every_n_steps': 1}, 'max_time_per_run': None, 'seconds_to_sleep': 5.0, 'create_straggler_detection_callback': False, 'straggler_detection_params': {'report_time_interval': 300.0, 'calc_relative_gpu_perf': True, 'calc_individual_gpu_perf': True, 'num_gpu_perf_scores_to_log': 5, 'gpu_relative_perf_threshold': 0.7, 'gpu_individual_perf_threshold': 0.7, 'stop_if_detected': False}, 'create_fault_tolerance_callback': False, 'fault_tolerance': {'workload_check_interval': 5.0, 'initial_rank_heartbeat_timeout': 3600.0, 'rank_heartbeat_timeout': 2700.0, 'calculate_timeouts': True, 'safety_factor': 5.0, 'rank_termination_signal': <Signals.SIGKILL: 9>, 'log_level': 'INFO', 'max_rank_restarts': 0, 'max_subsequent_job_failures': 0, 'additional_ft_launcher_args': '', 'simulated_fault': None}, 'log_tflops_per_sec_per_gpu': True}\n",
      "[NeMo I 2025-07-18 16:10:56 exp_manager:622] Experiments will be logged at experiments/Transducer-Model/2025-07-18_16-10-56\n",
      "[NeMo I 2025-07-18 16:10:56 exp_manager:1213] TensorboardLogger has been set up\n",
      "[NeMo I 2025-07-18 16:10:56 exp_manager:767] TFLOPs per sec per GPU will be calculated, conditioned on supported models. Defaults to -1 upon failure.\n"
     ]
    }
   ],
   "source": [
    "# Prepare NeMo's Experiment manager to handle checkpoint saving and logging for us\n",
    "from nemo.utils import exp_manager\n",
    "\n",
    "# Environment variable generally used for multi-node multi-gpu training.\n",
    "# In notebook environments, this flag is unnecessary and can cause logs of multiple training runs to overwrite each other.\n",
    "os.environ.pop('NEMO_EXPM_VERSION', None)\n",
    "\n",
    "exp_config = exp_manager.ExpManagerConfig(\n",
    "    exp_dir=f'experiments/',\n",
    "    name=f\"Transducer-Model\",\n",
    "    checkpoint_callback_params=exp_manager.CallbackParams(\n",
    "        monitor=\"val_wer\",\n",
    "        mode=\"min\",\n",
    "        always_save_nemo=True,\n",
    "        save_best_model=True,\n",
    "    ),\n",
    ")\n",
    "\n",
    "exp_config = OmegaConf.structured(exp_config)\n",
    "\n",
    "logdir = exp_manager.exp_manager(trainer, exp_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06b5f4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use TensorBoard, please use this notebook in a Google Colab environment.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  from google import colab\n",
    "  COLAB_ENV = True\n",
    "except (ImportError, ModuleNotFoundError):\n",
    "  COLAB_ENV = False\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "if COLAB_ENV:\n",
    "  %load_ext tensorboard\n",
    "  %tensorboard --logdir /content/experiments/Transducer-Model/\n",
    "else:\n",
    "  print(\"To use TensorBoard, please use this notebook in a Google Colab environment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7129066b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Release resources prior to training\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "if accelerator == 'gpu':\n",
    "  torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3f5924",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-07-18 16:10:56 modelPT:802] Optimizer config = Novograd (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: [0.9, 0.0]\n",
      "        eps: 1e-08\n",
      "        grad_averaging: False\n",
      "        lr: 0.05\n",
      "        weight_decay: 0.001\n",
      "    )\n",
      "[NeMo I 2025-07-18 16:10:56 lr_scheduler:950] Scheduler \"<nemo.core.optim.lr_scheduler.CosineAnnealing object at 0x75edecee1660>\" \n",
      "    will be used during training (effective maximum steps = 600) - \n",
      "    Parameters : \n",
      "    (warmup_steps: null\n",
      "    warmup_ratio: null\n",
      "    min_lr: 1.0e-06\n",
      "    last_epoch: -1\n",
      "    max_steps: 600\n",
      "    )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name              | Type                              | Params | Mode \n",
      "--------------------------------------------------------------------------------\n",
      "0 | preprocessor      | AudioToMelSpectrogramPreprocessor | 0      | train\n",
      "1 | encoder           | ConformerEncoder                  | 5.1 M  | train\n",
      "2 | decoder           | RNNTDecoder                       | 3.3 M  | train\n",
      "3 | joint             | RNNTJoint                         | 565 K  | train\n",
      "4 | loss              | RNNTLoss                          | 0      | train\n",
      "5 | spec_augmentation | SpectrogramAugmentation           | 0      | train\n",
      "6 | wer               | WER                               | 0      | train\n",
      "--------------------------------------------------------------------------------\n",
      "9.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "9.0 M     Total params\n",
      "35.964    Total estimated model params size (MB)\n",
      "201       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s][NeMo I 2025-07-18 16:10:57 optional_cuda_graphs:79] Enabled CUDA graphs for module <class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>.decoding.decoding\n",
      "[NeMo I 2025-07-18 16:10:57 optional_cuda_graphs:79] Enabled CUDA graphs for module <class 'nemo.collections.asr.metrics.wer.WER'>joint._wer.decoding.decoding\n",
      "Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:01<00:00,  1.30it/s][NeMo I 2025-07-18 16:10:58 optional_cuda_graphs:53] Disabled CUDA graphs for module <class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>.decoding.decoding\n",
      "[NeMo I 2025-07-18 16:10:58 optional_cuda_graphs:53] Disabled CUDA graphs for module <class 'nemo.collections.asr.metrics.wer.WER'>joint._wer.decoding.decoding\n",
      "Training: |          | 0/? [00:00<?, ?it/s]                                [NeMo I 2025-07-18 16:10:59 preemption:56] Preemption requires torch distributed to be initialized, disabling preemption\n",
      "Epoch 0:   0%|          | 0/60 [00:00<?, ?it/s] [NeMo I 2025-07-18 16:10:59 optional_cuda_graphs:53] Disabled CUDA graphs for module <class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>.decoding.decoding\n",
      "[NeMo I 2025-07-18 16:10:59 optional_cuda_graphs:53] Disabled CUDA graphs for module <class 'nemo.collections.asr.metrics.wer.WER'>joint._wer.decoding.decoding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-07-18 16:11:00 nemo_logging:361] /home/ubuntu/miniconda3/envs/nemo/lib/python3.10/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 4 will likely result in GPU under-utilization due to low occupancy.\n",
      "      warn(NumbaPerformanceWarning(msg))\n",
      "    \n",
      "[NeMo W 2025-07-18 16:11:00 nemo_logging:361] /home/ubuntu/miniconda3/envs/nemo/lib/python3.10/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 4 will likely result in GPU under-utilization due to low occupancy.\n",
      "      warn(NumbaPerformanceWarning(msg))\n",
      "    \n",
      "[NeMo W 2025-07-18 16:11:01 nemo_logging:361] /home/ubuntu/miniconda3/envs/nemo/lib/python3.10/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
      "      warn(NumbaPerformanceWarning(msg))\n",
      "    \n",
      "[NeMo W 2025-07-18 16:11:01 nemo_logging:361] /home/ubuntu/miniconda3/envs/nemo/lib/python3.10/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 4 will likely result in GPU under-utilization due to low occupancy.\n",
      "      warn(NumbaPerformanceWarning(msg))\n",
      "    \n",
      "[NeMo W 2025-07-18 16:11:01 nemo_logging:361] /home/ubuntu/miniconda3/envs/nemo/lib/python3.10/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
      "      warn(NumbaPerformanceWarning(msg))\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 60/60 [00:10<00:00,  5.77it/s, v_num=0-56, train_step_timing in s=0.108][NeMo I 2025-07-18 16:11:09 optional_cuda_graphs:79] Enabled CUDA graphs for module <class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>.decoding.decoding\n",
      "[NeMo I 2025-07-18 16:11:09 optional_cuda_graphs:79] Enabled CUDA graphs for module <class 'nemo.collections.asr.metrics.wer.WER'>joint._wer.decoding.decoding\n",
      "Epoch 1:   0%|          | 0/60 [00:00<?, ?it/s, v_num=0-56, train_step_timing in s=0.108]         [NeMo I 2025-07-18 16:11:09 optional_cuda_graphs:53] Disabled CUDA graphs for module <class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>.decoding.decoding\n",
      "[NeMo I 2025-07-18 16:11:09 optional_cuda_graphs:53] Disabled CUDA graphs for module <class 'nemo.collections.asr.metrics.wer.WER'>joint._wer.decoding.decoding\n",
      "Epoch 1: 100%|██████████| 60/60 [00:08<00:00,  6.93it/s, v_num=0-56, train_step_timing in s=0.113][NeMo I 2025-07-18 16:11:18 optional_cuda_graphs:79] Enabled CUDA graphs for module <class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>.decoding.decoding\n",
      "[NeMo I 2025-07-18 16:11:18 optional_cuda_graphs:79] Enabled CUDA graphs for module <class 'nemo.collections.asr.metrics.wer.WER'>joint._wer.decoding.decoding\n",
      "[NeMo I 2025-07-18 16:11:19 optional_cuda_graphs:53] Disabled CUDA graphs for module <class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>.decoding.decoding\n",
      "[NeMo I 2025-07-18 16:11:19 optional_cuda_graphs:53] Disabled CUDA graphs for module <class 'nemo.collections.asr.metrics.wer.WER'>joint._wer.decoding.decoding\n",
      "Epoch 1: 100%|██████████| 60/60 [00:10<00:00,  5.83it/s, v_num=0-56, train_step_timing in s=0.113]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 120: 'val_wer' reached 1.00000 (best 1.00000), saving model to '/home/ubuntu/nvidia_nemo/tutorials/asr/experiments/Transducer-Model/2025-07-18_16-10-56/checkpoints/Transducer-Model--val_wer=1.0000-epoch=1.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-07-18 16:11:19 nemo_model_checkpoint:546] Checkpoint save for step 120 started at 1752855079.9710252.\n",
      "[NeMo I 2025-07-18 16:11:20 nemo_model_checkpoint:546] Checkpoint save for step 120 started at 1752855080.3671467.\n",
      "[NeMo I 2025-07-18 16:11:20 nemo_model_checkpoint:236] New best .nemo model saved to: /home/ubuntu/nvidia_nemo/tutorials/asr/experiments/Transducer-Model/2025-07-18_16-10-56/checkpoints/Transducer-Model.nemo\n",
      "Epoch 1: 100%|██████████| 60/60 [00:11<00:00,  5.29it/s, v_num=0-56, train_step_timing in s=0.113][NeMo I 2025-07-18 16:11:21 optional_cuda_graphs:79] Enabled CUDA graphs for module <class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>.decoding.decoding\n",
      "[NeMo I 2025-07-18 16:11:21 optional_cuda_graphs:79] Enabled CUDA graphs for module <class 'nemo.collections.asr.metrics.wer.WER'>joint._wer.decoding.decoding\n",
      "Epoch 2:   0%|          | 0/60 [00:00<?, ?it/s, v_num=0-56, train_step_timing in s=0.113]         [NeMo I 2025-07-18 16:11:21 optional_cuda_graphs:53] Disabled CUDA graphs for module <class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>.decoding.decoding\n",
      "[NeMo I 2025-07-18 16:11:21 optional_cuda_graphs:53] Disabled CUDA graphs for module <class 'nemo.collections.asr.metrics.wer.WER'>joint._wer.decoding.decoding\n",
      "Epoch 2: 100%|██████████| 60/60 [00:08<00:00,  6.87it/s, v_num=0-56, train_step_timing in s=0.109][NeMo I 2025-07-18 16:11:29 optional_cuda_graphs:79] Enabled CUDA graphs for module <class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>.decoding.decoding\n",
      "[NeMo I 2025-07-18 16:11:29 optional_cuda_graphs:79] Enabled CUDA graphs for module <class 'nemo.collections.asr.metrics.wer.WER'>joint._wer.decoding.decoding\n",
      "Epoch 3:   0%|          | 0/60 [00:00<?, ?it/s, v_num=0-56, train_step_timing in s=0.109]         [NeMo I 2025-07-18 16:11:29 optional_cuda_graphs:53] Disabled CUDA graphs for module <class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>.decoding.decoding\n",
      "[NeMo I 2025-07-18 16:11:29 optional_cuda_graphs:53] Disabled CUDA graphs for module <class 'nemo.collections.asr.metrics.wer.WER'>joint._wer.decoding.decoding\n",
      "Epoch 3: 100%|██████████| 60/60 [00:08<00:00,  6.89it/s, v_num=0-56, train_step_timing in s=0.108][NeMo I 2025-07-18 16:11:39 optional_cuda_graphs:79] Enabled CUDA graphs for module <class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>.decoding.decoding\n",
      "[NeMo I 2025-07-18 16:11:39 optional_cuda_graphs:79] Enabled CUDA graphs for module <class 'nemo.collections.asr.metrics.wer.WER'>joint._wer.decoding.decoding\n",
      "[NeMo I 2025-07-18 16:11:40 optional_cuda_graphs:53] Disabled CUDA graphs for module <class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>.decoding.decoding\n",
      "[NeMo I 2025-07-18 16:11:40 optional_cuda_graphs:53] Disabled CUDA graphs for module <class 'nemo.collections.asr.metrics.wer.WER'>joint._wer.decoding.decoding\n",
      "Epoch 3: 100%|██████████| 60/60 [00:10<00:00,  5.78it/s, v_num=0-56, train_step_timing in s=0.108]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 240: 'val_wer' reached 1.00000 (best 1.00000), saving model to '/home/ubuntu/nvidia_nemo/tutorials/asr/experiments/Transducer-Model/2025-07-18_16-10-56/checkpoints/Transducer-Model--val_wer=1.0000-epoch=3.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-07-18 16:11:40 nemo_model_checkpoint:546] Checkpoint save for step 240 started at 1752855100.1497211.\n",
      "[NeMo I 2025-07-18 16:11:40 nemo_model_checkpoint:546] Checkpoint save for step 240 started at 1752855100.5654378.\n",
      "Epoch 3: 100%|██████████| 60/60 [00:11<00:00,  5.38it/s, v_num=0-56, train_step_timing in s=0.108][NeMo I 2025-07-18 16:11:40 optional_cuda_graphs:79] Enabled CUDA graphs for module <class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>.decoding.decoding\n",
      "[NeMo I 2025-07-18 16:11:40 optional_cuda_graphs:79] Enabled CUDA graphs for module <class 'nemo.collections.asr.metrics.wer.WER'>joint._wer.decoding.decoding\n",
      "Epoch 4:   0%|          | 0/60 [00:00<?, ?it/s, v_num=0-56, train_step_timing in s=0.108]         [NeMo I 2025-07-18 16:11:40 optional_cuda_graphs:53] Disabled CUDA graphs for module <class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>.decoding.decoding\n",
      "[NeMo I 2025-07-18 16:11:40 optional_cuda_graphs:53] Disabled CUDA graphs for module <class 'nemo.collections.asr.metrics.wer.WER'>joint._wer.decoding.decoding\n",
      "Epoch 4: 100%|██████████| 60/60 [00:08<00:00,  6.77it/s, v_num=0-56, train_step_timing in s=0.122][NeMo I 2025-07-18 16:11:49 optional_cuda_graphs:79] Enabled CUDA graphs for module <class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>.decoding.decoding\n",
      "[NeMo I 2025-07-18 16:11:49 optional_cuda_graphs:79] Enabled CUDA graphs for module <class 'nemo.collections.asr.metrics.wer.WER'>joint._wer.decoding.decoding\n",
      "Epoch 5:   0%|          | 0/60 [00:00<?, ?it/s, v_num=0-56, train_step_timing in s=0.122]         [NeMo I 2025-07-18 16:11:49 optional_cuda_graphs:53] Disabled CUDA graphs for module <class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>.decoding.decoding\n",
      "[NeMo I 2025-07-18 16:11:49 optional_cuda_graphs:53] Disabled CUDA graphs for module <class 'nemo.collections.asr.metrics.wer.WER'>joint._wer.decoding.decoding\n",
      "Epoch 5: 100%|██████████| 60/60 [00:09<00:00,  6.66it/s, v_num=0-56, train_step_timing in s=0.103][NeMo I 2025-07-18 16:11:59 optional_cuda_graphs:79] Enabled CUDA graphs for module <class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>.decoding.decoding\n",
      "[NeMo I 2025-07-18 16:11:59 optional_cuda_graphs:79] Enabled CUDA graphs for module <class 'nemo.collections.asr.metrics.wer.WER'>joint._wer.decoding.decoding\n",
      "[NeMo I 2025-07-18 16:12:00 optional_cuda_graphs:53] Disabled CUDA graphs for module <class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>.decoding.decoding\n",
      "[NeMo I 2025-07-18 16:12:00 optional_cuda_graphs:53] Disabled CUDA graphs for module <class 'nemo.collections.asr.metrics.wer.WER'>joint._wer.decoding.decoding\n",
      "Epoch 5: 100%|██████████| 60/60 [00:10<00:00,  5.54it/s, v_num=0-56, train_step_timing in s=0.103]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 360: 'val_wer' reached 0.97413 (best 0.97413), saving model to '/home/ubuntu/nvidia_nemo/tutorials/asr/experiments/Transducer-Model/2025-07-18_16-10-56/checkpoints/Transducer-Model--val_wer=0.9741-epoch=5.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-07-18 16:12:00 nemo_model_checkpoint:546] Checkpoint save for step 360 started at 1752855120.60349.\n",
      "[NeMo I 2025-07-18 16:12:01 nemo_model_checkpoint:546] Checkpoint save for step 360 started at 1752855121.0226743.\n",
      "[NeMo I 2025-07-18 16:12:01 nemo_model_checkpoint:316] /home/ubuntu/nvidia_nemo/tutorials/asr/experiments/Transducer-Model/2025-07-18_16-10-56/checkpoints/Transducer-Model.nemo already exists, moving existing checkpoint to /home/ubuntu/nvidia_nemo/tutorials/asr/experiments/Transducer-Model/2025-07-18_16-10-56/checkpoints/Transducer-Model-v1.nemo\n",
      "[NeMo I 2025-07-18 16:12:01 nemo_model_checkpoint:236] New best .nemo model saved to: /home/ubuntu/nvidia_nemo/tutorials/asr/experiments/Transducer-Model/2025-07-18_16-10-56/checkpoints/Transducer-Model.nemo\n",
      "[NeMo I 2025-07-18 16:12:01 nemo_model_checkpoint:245] Removing old .nemo backup /home/ubuntu/nvidia_nemo/tutorials/asr/experiments/Transducer-Model/2025-07-18_16-10-56/checkpoints/Transducer-Model-v1.nemo\n",
      "Epoch 5: 100%|██████████| 60/60 [00:11<00:00,  5.04it/s, v_num=0-56, train_step_timing in s=0.103][NeMo I 2025-07-18 16:12:01 optional_cuda_graphs:79] Enabled CUDA graphs for module <class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>.decoding.decoding\n",
      "[NeMo I 2025-07-18 16:12:01 optional_cuda_graphs:79] Enabled CUDA graphs for module <class 'nemo.collections.asr.metrics.wer.WER'>joint._wer.decoding.decoding\n",
      "Epoch 6:   0%|          | 0/60 [00:00<?, ?it/s, v_num=0-56, train_step_timing in s=0.103]         [NeMo I 2025-07-18 16:12:01 optional_cuda_graphs:53] Disabled CUDA graphs for module <class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>.decoding.decoding\n",
      "[NeMo I 2025-07-18 16:12:01 optional_cuda_graphs:53] Disabled CUDA graphs for module <class 'nemo.collections.asr.metrics.wer.WER'>joint._wer.decoding.decoding\n",
      "Epoch 6: 100%|██████████| 60/60 [00:09<00:00,  6.50it/s, v_num=0-56, train_step_timing in s=0.118][NeMo I 2025-07-18 16:12:10 optional_cuda_graphs:79] Enabled CUDA graphs for module <class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>.decoding.decoding\n",
      "[NeMo I 2025-07-18 16:12:10 optional_cuda_graphs:79] Enabled CUDA graphs for module <class 'nemo.collections.asr.metrics.wer.WER'>joint._wer.decoding.decoding\n",
      "Epoch 7:   0%|          | 0/60 [00:00<?, ?it/s, v_num=0-56, train_step_timing in s=0.118]         [NeMo I 2025-07-18 16:12:10 optional_cuda_graphs:53] Disabled CUDA graphs for module <class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>.decoding.decoding\n",
      "[NeMo I 2025-07-18 16:12:10 optional_cuda_graphs:53] Disabled CUDA graphs for module <class 'nemo.collections.asr.metrics.wer.WER'>joint._wer.decoding.decoding\n",
      "Epoch 7: 100%|██████████| 60/60 [00:09<00:00,  6.42it/s, v_num=0-56, train_step_timing in s=0.125][NeMo I 2025-07-18 16:12:20 optional_cuda_graphs:79] Enabled CUDA graphs for module <class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>.decoding.decoding\n",
      "[NeMo I 2025-07-18 16:12:20 optional_cuda_graphs:79] Enabled CUDA graphs for module <class 'nemo.collections.asr.metrics.wer.WER'>joint._wer.decoding.decoding\n",
      "[NeMo I 2025-07-18 16:12:22 optional_cuda_graphs:53] Disabled CUDA graphs for module <class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>.decoding.decoding\n",
      "[NeMo I 2025-07-18 16:12:22 optional_cuda_graphs:53] Disabled CUDA graphs for module <class 'nemo.collections.asr.metrics.wer.WER'>joint._wer.decoding.decoding\n",
      "Epoch 7: 100%|██████████| 60/60 [00:11<00:00,  5.41it/s, v_num=0-56, train_step_timing in s=0.125]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 480: 'val_wer' reached 0.95213 (best 0.95213), saving model to '/home/ubuntu/nvidia_nemo/tutorials/asr/experiments/Transducer-Model/2025-07-18_16-10-56/checkpoints/Transducer-Model--val_wer=0.9521-epoch=7.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-07-18 16:12:22 nemo_model_checkpoint:546] Checkpoint save for step 480 started at 1752855142.0145965.\n",
      "[NeMo I 2025-07-18 16:12:22 nemo_model_checkpoint:546] Checkpoint save for step 480 started at 1752855142.4441109.\n",
      "[NeMo I 2025-07-18 16:12:22 nemo_model_checkpoint:316] /home/ubuntu/nvidia_nemo/tutorials/asr/experiments/Transducer-Model/2025-07-18_16-10-56/checkpoints/Transducer-Model.nemo already exists, moving existing checkpoint to /home/ubuntu/nvidia_nemo/tutorials/asr/experiments/Transducer-Model/2025-07-18_16-10-56/checkpoints/Transducer-Model-v1.nemo\n",
      "[NeMo I 2025-07-18 16:12:22 nemo_model_checkpoint:236] New best .nemo model saved to: /home/ubuntu/nvidia_nemo/tutorials/asr/experiments/Transducer-Model/2025-07-18_16-10-56/checkpoints/Transducer-Model.nemo\n",
      "[NeMo I 2025-07-18 16:12:22 nemo_model_checkpoint:245] Removing old .nemo backup /home/ubuntu/nvidia_nemo/tutorials/asr/experiments/Transducer-Model/2025-07-18_16-10-56/checkpoints/Transducer-Model-v1.nemo\n",
      "Epoch 7: 100%|██████████| 60/60 [00:12<00:00,  4.92it/s, v_num=0-56, train_step_timing in s=0.125][NeMo I 2025-07-18 16:12:23 optional_cuda_graphs:79] Enabled CUDA graphs for module <class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>.decoding.decoding\n",
      "[NeMo I 2025-07-18 16:12:23 optional_cuda_graphs:79] Enabled CUDA graphs for module <class 'nemo.collections.asr.metrics.wer.WER'>joint._wer.decoding.decoding\n",
      "Epoch 8:   0%|          | 0/60 [00:00<?, ?it/s, v_num=0-56, train_step_timing in s=0.125]         [NeMo I 2025-07-18 16:12:23 optional_cuda_graphs:53] Disabled CUDA graphs for module <class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>.decoding.decoding\n",
      "[NeMo I 2025-07-18 16:12:23 optional_cuda_graphs:53] Disabled CUDA graphs for module <class 'nemo.collections.asr.metrics.wer.WER'>joint._wer.decoding.decoding\n",
      "Epoch 8: 100%|██████████| 60/60 [00:09<00:00,  6.43it/s, v_num=0-56, train_step_timing in s=0.118][NeMo I 2025-07-18 16:12:32 optional_cuda_graphs:79] Enabled CUDA graphs for module <class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>.decoding.decoding\n",
      "[NeMo I 2025-07-18 16:12:32 optional_cuda_graphs:79] Enabled CUDA graphs for module <class 'nemo.collections.asr.metrics.wer.WER'>joint._wer.decoding.decoding\n",
      "Epoch 9:   0%|          | 0/60 [00:00<?, ?it/s, v_num=0-56, train_step_timing in s=0.118]         [NeMo I 2025-07-18 16:12:32 optional_cuda_graphs:53] Disabled CUDA graphs for module <class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>.decoding.decoding\n",
      "[NeMo I 2025-07-18 16:12:32 optional_cuda_graphs:53] Disabled CUDA graphs for module <class 'nemo.collections.asr.metrics.wer.WER'>joint._wer.decoding.decoding\n",
      "Epoch 9: 100%|██████████| 60/60 [00:09<00:00,  6.25it/s, v_num=0-56, train_step_timing in s=0.118][NeMo I 2025-07-18 16:12:42 optional_cuda_graphs:79] Enabled CUDA graphs for module <class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>.decoding.decoding\n",
      "[NeMo I 2025-07-18 16:12:42 optional_cuda_graphs:79] Enabled CUDA graphs for module <class 'nemo.collections.asr.metrics.wer.WER'>joint._wer.decoding.decoding\n",
      "[NeMo I 2025-07-18 16:12:43 optional_cuda_graphs:53] Disabled CUDA graphs for module <class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>.decoding.decoding\n",
      "[NeMo I 2025-07-18 16:12:43 optional_cuda_graphs:53] Disabled CUDA graphs for module <class 'nemo.collections.asr.metrics.wer.WER'>joint._wer.decoding.decoding\n",
      "Epoch 9: 100%|██████████| 60/60 [00:11<00:00,  5.24it/s, v_num=0-56, train_step_timing in s=0.118]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 600: 'val_wer' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-07-18 16:12:43 nemo_model_checkpoint:546] Checkpoint save for step 600 started at 1752855163.8975737.\n",
      "Epoch 9: 100%|██████████| 60/60 [00:11<00:00,  5.06it/s, v_num=0-56, train_step_timing in s=0.118][NeMo I 2025-07-18 16:12:44 optional_cuda_graphs:79] Enabled CUDA graphs for module <class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>.decoding.decoding\n",
      "[NeMo I 2025-07-18 16:12:44 optional_cuda_graphs:79] Enabled CUDA graphs for module <class 'nemo.collections.asr.metrics.wer.WER'>joint._wer.decoding.decoding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 60/60 [00:11<00:00,  5.06it/s, v_num=0-56, train_step_timing in s=0.118]\n",
      "[NeMo I 2025-07-18 16:12:44 nemo_model_checkpoint:546] Checkpoint save for step 600 started at 1752855164.3016355.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /home/ubuntu/nvidia_nemo/tutorials/asr/experiments/Transducer-Model/2025-07-18_16-10-56/checkpoints/Transducer-Model--val_wer=0.9521-epoch=7.ckpt\n",
      "Restored all states from the checkpoint at /home/ubuntu/nvidia_nemo/tutorials/asr/experiments/Transducer-Model/2025-07-18_16-10-56/checkpoints/Transducer-Model--val_wer=0.9521-epoch=7.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-07-18 16:12:44 nemo_model_checkpoint:316] /home/ubuntu/nvidia_nemo/tutorials/asr/experiments/Transducer-Model/2025-07-18_16-10-56/checkpoints/Transducer-Model.nemo already exists, moving existing checkpoint to /home/ubuntu/nvidia_nemo/tutorials/asr/experiments/Transducer-Model/2025-07-18_16-10-56/checkpoints/Transducer-Model-v1.nemo\n",
      "[NeMo I 2025-07-18 16:12:45 nemo_model_checkpoint:288] Removing old .nemo backup /home/ubuntu/nvidia_nemo/tutorials/asr/experiments/Transducer-Model/2025-07-18_16-10-56/checkpoints/Transducer-Model-v1.nemo\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.fit(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nemo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
